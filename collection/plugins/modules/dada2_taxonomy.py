#!/usr/bin/python

# Copyright: (c) 2019, Tanner Dowhy <tanner.dowhy@usask.ca>
# GNU General Public License v3.0+ (see COPYING or https://www.gnu.org/licenses/gpl-3.0.txt

from __future__ import absolute_import, division, print_function
__metaclass__ = type

ANSIBLE_METADATA = {'metadata_version': '1.1'}

DOCUMENTATION = '''
---
module: This is a module to remove chimeras and assign taxonomy to an ASV table generated by DADA2.
version_added: "2.7"
author: "Tanner Dowhy (@TannerDowhy)"
options:
    input_rds:
        description: 
            -Input .rds ASV table from DADA2 sample inference step.
        required: True
    executable:
        description:
            - The path to the Cutadapt executable. Should be specified but if
              it isn't it will be located.
        required: false
    base_dir:
        description:
            - The path to where the analysis is to take place.
        required: true
        default: Home directory. This needs to be changed if the user doesn't
                 have write access to the home directory or if the environment
                 requires a different path such as in the case of Compute Canada.
    hpc: 
        description: 
            - Boolean variable on whether the run is executed on a regular or HPC machine.
        required: false
        default: false
    chimera_method:
        description:
            - The chimera method to use: consensus, pooled, or per-sample.
        required: false
        default: consensus
    training_set:
        description:
            - The path to the training set for assigning taxonomy.
        required: true
    output_seqtab:
        description:
            - Name of the output ASV table:
        required: false
        default: seqtab_final
    output_taxonomy:
        description:
            - Name of the output taxonomy table
        required: false
        default: taxonomy_final
    slurm_spec: 
        description:
            - The SLURM options if hpc was set to true.
        required: false
        note: Required if hpc was set to true.
notes:
    - Requires DADA2 Sample Inference as input. 
'''

EXAMPLES = '''
- name: Run DADA2 Taxonomy module
  dada2_taxonomy:
    input_rds: "{{ base_path }}/.biolighthouse/DADA2/seqtab.rds"
    base_dir: "{{ base_path }}"
    training_set: "{{ base_path }}/.biolighthouse/DADA2/silva_nr_v132_train_set.fa.gz"
    hpc: False

- name: Run DADA2 Taxonomy module
  dada2_taxonomy:
    input_rds: "{{ base_path }}/.biolighthouse/DADA2/seqtab.rds"
    base_dir: "{{ base_path }}"
    training_set: "{{ base_path }}/.biolighthouse/DADA2/silva_nr_v132_train_set.fa.gz"
    chimera_method: pooled
    hpc: True
    slurm_spec:
      account: "{{ account }}"
      job_name: "biolighthouse"
      mem: 32G
      time: 48:00
      num_nodes: 4
      tasks_per_node: 32
'''

RETURN = '''
cmd:
    description: The command that was executed
    type: str
out:
    description: The output message that the module generates
err:
    description: The error message that the modules generates
'''

from ansible.module_utils.basic import AnsibleModule
import imp
import glob
import subprocess
from os.path import expanduser

def dada2_taxonomy_arg_spec(slurm, **kwargs):
    spec = dict(
        input_rds=dict(type='path', required=True),
        hpc=dict(type='bool', default=False),
        executable=dict(type='path', default=None, required=False),
        base_dir=dict(type='path', default=None, required=False),
        chimera_method=dict(type='str', default='consensus', choices=['consensus', 'pooled', 'per-sample']),
        training_set=dict(type='path', required=True),
        output_seqtab=dict(type='str', default='seqtab_final'),
        output_taxonomy=dict(type='str', default='taxonomy_final'),
        slurm_spec=dict(type='dict', default=slurm.slurm_arg_spec(), required=False)
    )
    spec.update(kwargs)
    return spec

def build_taxonomy_command(module, dada2_path, executable):
    cmd = [executable, '%s/taxonomy.R' % dada2_path, '%s/.biolighthouse/software/R/library' % module.params['base_dir'],
        module.params['input_rds'], module.params['chimera_method'], module.params['training_set'], '%s/%s.csv' % (dada2_path, module.params['output_seqtab']),
        '%s/%s.csv' % (dada2_path, module.params['output_taxonomy']), '%s/%s.rds' % (dada2_path, module.params['output_seqtab']), '%s/%s.rds'
        % (dada2_path, module.params['output_taxonomy'])]
    return cmd

def main():
    slurm = imp.load_source('utils.slurm', '/tmp/biol/slurm.py')
    tool = imp.load_source('utils.tool', '/tmp/biol/tool.py')
    argument_spec=dada2_taxonomy_arg_spec(slurm)
    module = AnsibleModule(argument_spec,
                           supports_check_mode=True
                           )
    # if module.params['hpc']:
    result = dict(
        changed=False,
        rc = '',
        out= '',
        err='',
        cmd=''
    )
    dada2 = tool.Tool(module.params['base_dir'], 'rscript')
    executable = dada2.get_executable_path(module)

    if module.check_mode:
        return result

    dada2_path = "%s/.biolighthouse/DADA2" % module.params['base_dir']

    cmd = build_taxonomy_command(module, dada2_path, executable)

    with open('%s/dada2_taxonomy.sh' % (dada2_path), 'w') as f:
        f.write('%s\n\n%s' % ('#!/bin/bash', ' '.join(cmd)))
        f.close()

    # if module.params['slurm_spec']['account'] is not None:
    import subprocess
    subprocess.call(['chmod', '0700', '%s/dada2_taxonomy.sh' % dada2_path])
    if module.params['hpc']:
        slurm_cmd = slurm.build_slurm_cmd(module)
        slurm_cmd.extend(['--output=%s/dada2_taxonomy.report' % dada2_path, '%s/dada2_taxonomy.sh' % dada2_path])
        rc, out, err = module.run_command(slurm_cmd, cwd=dada2_path)
    else:
        rc, out, err = module.run_command(cmd, cwd=dada2_path)
    result['changed'] = True
    result['out'] = out
    result['err'] = err
    result['rc'] = rc

    module.exit_json(**result)

if __name__ == '__main__':
    main()
